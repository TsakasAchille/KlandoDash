"""
Test du nouveau syst√®me de validation moderne avec Pydantic
"""
import json
import os
from dash_apps.services.config_validator import ConfigValidator
from dash_apps.models.config_models import MainConfig
from dash_apps.utils.validation_utils import validate_json_file


def test_config_validation():
    """Test de validation d'une configuration existante"""
    print("üß™ TEST DU SYST√àME DE VALIDATION MODERNE")
    print("=" * 60)
    
    # Chemin vers la configuration existante
    config_path = "/home/achille.tsakas/Klando/KlandoDash2/KlandoDash/dash_apps/config/trip_details_config.json"
    
    if not os.path.exists(config_path):
        print(f"‚ùå Fichier de configuration non trouv√©: {config_path}")
        return False
    
    print(f"üìÅ Configuration test√©e: {config_path}")
    print()
    
    # Test 1: Validation Pydantic de base
    print("1Ô∏è‚É£ VALIDATION PYDANTIC DE BASE")
    result = validate_json_file(MainConfig, config_path)
    
    if result.success:
        print("‚úÖ Configuration valide selon les mod√®les Pydantic")
    else:
        print("‚ùå Erreurs de validation Pydantic:")
        for error in result.errors:
            print(f"   ‚Ä¢ {error.get('field', 'unknown')}: {error.get('message', 'Erreur inconnue')}")
    print()
    
    # Test 2: Validation compl√®te avec sch√©ma DB
    print("2Ô∏è‚É£ VALIDATION COMPL√àTE (PYDANTIC + SCH√âMA DB)")
    full_result = ConfigValidator.validate_config_file(config_path)
    
    if full_result.success:
        print("‚úÖ Configuration compl√®tement valide")
    else:
        print("‚ùå Erreurs d√©tect√©es:")
        for error in full_result.errors:
            print(f"   ‚Ä¢ {error.get('field', 'unknown')}: {error.get('message', 'Erreur inconnue')}")
    print()
    
    # Test 3: Rapport d√©taill√©
    print("3Ô∏è‚É£ RAPPORT D√âTAILL√â")
    report = ConfigValidator.get_validation_report(config_path)
    print(report)
    print()
    
    # Test 4: R√©sum√© du sch√©ma
    print("4Ô∏è‚É£ R√âSUM√â DU SCH√âMA")
    schema_summary = ConfigValidator.get_schema_summary()
    if 'error' not in schema_summary:
        print(f"üìä Total colonnes: {schema_summary['total_columns']}")
        print(f"üìä Colonnes obligatoires: {len(schema_summary['required_columns'])}")
        print(f"üìä Colonnes datetime: {len(schema_summary['datetime_columns'])}")
        print(f"üìä Colonnes text: {len(schema_summary['text_columns'])}")
    else:
        print(f"‚ùå {schema_summary['error']}")
    
    return full_result.success


def create_test_config():
    """Cr√©e une configuration de test pour valider le syst√®me"""
    test_config = {
        "trip_details": {
            "cache": {
                "enabled": True,
                "ttl_seconds": 300,
                "key_prefix": "trip_details"
            },
            "data_source": {
                "primary": "rest_api",
                "fallback": "sql",
                "timeout_seconds": 30
            },
            "validation": {
                "enabled": True,
                "schema_file": "trips_scheme.json",
                "strict_mode": False,
                "auto_fix": True
            },
            "rendering": {
                "sections": {
                    "basic_info": {
                        "title": "Informations de base",
                        "collapsible": False,
                        "default_collapsed": False,
                        "fields": {
                            "trip_id": {
                                "type": "integer",
                                "label": "ID du trajet",
                                "required": True
                            },
                            "start_time": {
                                "type": "datetime",
                                "label": "Heure de d√©but",
                                "required": True,
                                "format": "iso"
                            },
                            "end_time": {
                                "type": "datetime",
                                "label": "Heure de fin",
                                "required": False,
                                "format": "iso"
                            }
                        }
                    },
                    "location_info": {
                        "title": "Informations de localisation",
                        "collapsible": True,
                        "default_collapsed": False,
                        "fields": {
                            "start_latitude": {
                                "type": "float",
                                "label": "Latitude de d√©part",
                                "required": False
                            },
                            "start_longitude": {
                                "type": "float",
                                "label": "Longitude de d√©part",
                                "required": False
                            }
                        }
                    }
                }
            }
        }
    }
    
    test_path = "/tmp/test_config.json"
    with open(test_path, 'w', encoding='utf-8') as f:
        json.dump(test_config, f, indent=2, ensure_ascii=False)
    
    return test_path


def test_with_sample_config():
    """Test avec une configuration d'exemple"""
    print("\nüß™ TEST AVEC CONFIGURATION D'EXEMPLE")
    print("=" * 60)
    
    test_path = create_test_config()
    print(f"üìÅ Configuration de test cr√©√©e: {test_path}")
    
    # Validation de la configuration de test
    result = ConfigValidator.validate_config_file(test_path)
    
    if result.success:
        print("‚úÖ Configuration de test valide")
    else:
        print("‚ùå Erreurs dans la configuration de test:")
        for error in result.errors:
            print(f"   ‚Ä¢ {error.get('field', 'unknown')}: {error.get('message', 'Erreur inconnue')}")
    
    # Nettoyage
    os.unlink(test_path)
    
    return result.success


if __name__ == "__main__":
    print("üöÄ D√âMARRAGE DES TESTS DE VALIDATION MODERNE")
    print()
    
    # Test avec la configuration existante
    success1 = test_config_validation()
    
    # Test avec une configuration d'exemple
    success2 = test_with_sample_config()
    
    print("\n" + "=" * 60)
    print("üìã R√âSUM√â DES TESTS")
    print("=" * 60)
    print(f"Configuration existante: {'‚úÖ SUCC√àS' if success1 else '‚ùå √âCHEC'}")
    print(f"Configuration de test: {'‚úÖ SUCC√àS' if success2 else '‚ùå √âCHEC'}")
    
    if success1 and success2:
        print("\nüéâ TOUS LES TESTS R√âUSSIS - Le syst√®me de validation moderne fonctionne parfaitement!")
    else:
        print("\n‚ö†Ô∏è Certains tests ont √©chou√© - V√©rifiez les erreurs ci-dessus")
